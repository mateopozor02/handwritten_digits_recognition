{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se importan los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18c6975c7c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#Imprime los tamanios de la matriz, y_train.shape() devuelve una sola componente pues son los resultados. \n",
    "print(X_train.shape, y_train.shape)\n",
    "plt.title(y_train[0])\n",
    "plt.imshow(X_train[0], cmap= 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se expande la dimension de las matrices para que el algoritmo pueda trabajar con ellas\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "#Se normalizan las imagenes RBG diviendo entre 255\n",
    "X_train = X_train/255.0 \n",
    "X_test = X_test/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se convierten los vectores de resultados a matrices categoricas\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "#Fully connected output layer \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks para monitorear overfitting\n",
    "from keras import callbacks\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor= 'val_accuracy', min_delta= 0.01, patience= 4, verbose= 1)\n",
    "\n",
    "mc = callbacks.ModelCheckpoint(\"./mnist.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True)\n",
    "\n",
    "cb = [es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 2.4637 - accuracy: 0.1079\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17217, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 2.4633 - accuracy: 0.1079 - val_loss: 2.2550 - val_accuracy: 0.1722\n",
      "Epoch 2/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 2.1292 - accuracy: 0.2591\n",
      "Epoch 2: val_accuracy improved from 0.17217 to 0.35594, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 35ms/step - loss: 2.1290 - accuracy: 0.2590 - val_loss: 2.0044 - val_accuracy: 0.3559\n",
      "Epoch 3/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 1.9043 - accuracy: 0.4311\n",
      "Epoch 3: val_accuracy improved from 0.35594 to 0.49761, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 1.9041 - accuracy: 0.4312 - val_loss: 1.7925 - val_accuracy: 0.4976\n",
      "Epoch 4/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 1.6984 - accuracy: 0.5432\n",
      "Epoch 4: val_accuracy improved from 0.49761 to 0.58678, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 1.6981 - accuracy: 0.5433 - val_loss: 1.5924 - val_accuracy: 0.5868\n",
      "Epoch 5/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 1.5123 - accuracy: 0.6173\n",
      "Epoch 5: val_accuracy improved from 0.58678 to 0.64944, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 1.5121 - accuracy: 0.6174 - val_loss: 1.4156 - val_accuracy: 0.6494\n",
      "Epoch 6/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 1.3488 - accuracy: 0.6703\n",
      "Epoch 6: val_accuracy improved from 0.64944 to 0.70144, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 1.3486 - accuracy: 0.6703 - val_loss: 1.2606 - val_accuracy: 0.7014\n",
      "Epoch 7/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 1.2062 - accuracy: 0.7123\n",
      "Epoch 7: val_accuracy improved from 0.70144 to 0.74000, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 1.2061 - accuracy: 0.7124 - val_loss: 1.1258 - val_accuracy: 0.7400\n",
      "Epoch 8/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 1.0824 - accuracy: 0.7473\n",
      "Epoch 8: val_accuracy improved from 0.74000 to 0.76978, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 1.0823 - accuracy: 0.7472 - val_loss: 1.0096 - val_accuracy: 0.7698\n",
      "Epoch 9/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.9761 - accuracy: 0.7753\n",
      "Epoch 9: val_accuracy improved from 0.76978 to 0.79428, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.9760 - accuracy: 0.7753 - val_loss: 0.9098 - val_accuracy: 0.7943\n",
      "Epoch 10/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.8847 - accuracy: 0.7973\n",
      "Epoch 10: val_accuracy improved from 0.79428 to 0.81328, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.8846 - accuracy: 0.7973 - val_loss: 0.8244 - val_accuracy: 0.8133\n",
      "Epoch 11/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.8060 - accuracy: 0.8145\n",
      "Epoch 11: val_accuracy improved from 0.81328 to 0.82872, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.8058 - accuracy: 0.8145 - val_loss: 0.7512 - val_accuracy: 0.8287\n",
      "Epoch 12/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.7387 - accuracy: 0.8280\n",
      "Epoch 12: val_accuracy improved from 0.82872 to 0.84106, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.7385 - accuracy: 0.8280 - val_loss: 0.6889 - val_accuracy: 0.8411\n",
      "Epoch 13/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.8403\n",
      "Epoch 13: val_accuracy improved from 0.84106 to 0.85244, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.6806 - accuracy: 0.8403 - val_loss: 0.6352 - val_accuracy: 0.8524\n",
      "Epoch 14/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.6309 - accuracy: 0.8499\n",
      "Epoch 14: val_accuracy improved from 0.85244 to 0.86161, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.6308 - accuracy: 0.8499 - val_loss: 0.5895 - val_accuracy: 0.8616\n",
      "Epoch 15/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.5877 - accuracy: 0.8584\n",
      "Epoch 15: val_accuracy improved from 0.86161 to 0.86817, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.5878 - accuracy: 0.8584 - val_loss: 0.5501 - val_accuracy: 0.8682\n",
      "Epoch 16/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.5505 - accuracy: 0.8659\n",
      "Epoch 16: val_accuracy improved from 0.86817 to 0.87439, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.5505 - accuracy: 0.8660 - val_loss: 0.5159 - val_accuracy: 0.8744\n",
      "Epoch 17/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.5179 - accuracy: 0.8716\n",
      "Epoch 17: val_accuracy improved from 0.87439 to 0.88022, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 36ms/step - loss: 0.5179 - accuracy: 0.8716 - val_loss: 0.4859 - val_accuracy: 0.8802\n",
      "Epoch 18/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.4897 - accuracy: 0.8773\n",
      "Epoch 18: val_accuracy improved from 0.88022 to 0.88628, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.4894 - accuracy: 0.8774 - val_loss: 0.4600 - val_accuracy: 0.8863\n",
      "Epoch 19/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.8833\n",
      "Epoch 19: val_accuracy improved from 0.88628 to 0.89006, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.4643 - accuracy: 0.8831 - val_loss: 0.4370 - val_accuracy: 0.8901\n",
      "Epoch 20/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.8869\n",
      "Epoch 20: val_accuracy improved from 0.89006 to 0.89406, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.4423 - accuracy: 0.8869 - val_loss: 0.4169 - val_accuracy: 0.8941\n",
      "Epoch 21/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.4227 - accuracy: 0.8917\n",
      "Epoch 21: val_accuracy improved from 0.89406 to 0.89778, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.4226 - accuracy: 0.8917 - val_loss: 0.3993 - val_accuracy: 0.8978\n",
      "Epoch 22/50\n",
      "420/420 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8948\n",
      "Epoch 22: val_accuracy improved from 0.89778 to 0.90050, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.4049 - accuracy: 0.8948 - val_loss: 0.3830 - val_accuracy: 0.9005\n",
      "Epoch 23/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8984\n",
      "Epoch 23: val_accuracy improved from 0.90050 to 0.90317, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.3891 - accuracy: 0.8984 - val_loss: 0.3686 - val_accuracy: 0.9032\n",
      "Epoch 24/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.3752 - accuracy: 0.9011\n",
      "Epoch 24: val_accuracy improved from 0.90317 to 0.90583, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.3750 - accuracy: 0.9013 - val_loss: 0.3559 - val_accuracy: 0.9058\n",
      "Epoch 25/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.9037\n",
      "Epoch 25: val_accuracy improved from 0.90583 to 0.90844, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 16s 37ms/step - loss: 0.3621 - accuracy: 0.9036 - val_loss: 0.3439 - val_accuracy: 0.9084\n",
      "Epoch 26/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.3505 - accuracy: 0.9062\n",
      "Epoch 26: val_accuracy improved from 0.90844 to 0.91106, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.3504 - accuracy: 0.9062 - val_loss: 0.3336 - val_accuracy: 0.9111\n",
      "Epoch 27/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.9088\n",
      "Epoch 27: val_accuracy improved from 0.91106 to 0.91344, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.3398 - accuracy: 0.9088 - val_loss: 0.3238 - val_accuracy: 0.9134\n",
      "Epoch 28/50\n",
      "419/420 [============================>.] - ETA: 0s - loss: 0.3300 - accuracy: 0.9112\n",
      "Epoch 28: val_accuracy improved from 0.91344 to 0.91522, saving model to .\\mnist.h5\n",
      "420/420 [==============================] - 15s 37ms/step - loss: 0.3301 - accuracy: 0.9112 - val_loss: 0.3149 - val_accuracy: 0.9152\n",
      "Epoch 28: early stopping\n",
      "The model has successfully trained\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split= 0.3, callbacks= cb)\n",
    "print(\"The model has successfully trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30992984771728516\n",
      "Test accuracy: 0.9164999723434448\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e06ff7da33dc9620448857a90ad8b5f428f0d573d205a934d2841c8aee45ea32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
